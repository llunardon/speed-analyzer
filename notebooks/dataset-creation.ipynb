{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    inputs: in_paths  ---> list of input paths, where every path corresponds to a different label\n",
    "            out_paths ---> names of training, validation and test folders, in this order\n",
    "              ratios  ---> what fraction of the dataset goes into training, validation and testing\n",
    "              seed    ---> seed used for randomization \n",
    "\"\"\"\n",
    "def create_dataset(in_paths, labels, out_paths, ratios, seed):\n",
    "    if len(ratios) != 3 or len(out_paths) != 3:\n",
    "        print(\"Output configuration is wrong\")\n",
    "        return\n",
    "\n",
    "    if np.sum(ratios) > 1.0:\n",
    "        print(\"Sum of ratios must be less than 1\")\n",
    "        return\n",
    "\n",
    "    for out_path in out_paths:\n",
    "        if not os.path.exists(out_path): \n",
    "            os.makedirs(out_path) \n",
    "            print(f\"Created folder {out_path}\")\n",
    "        else:\n",
    "            utils.delete_folder(out_path)\n",
    "            os.makedirs(out_path) \n",
    "            print(f\"Substituted folder {out_path}\")\n",
    "    \n",
    "    for label_index, in_path in enumerate(in_paths):\n",
    "        # label = in_path.split('/')[-2]\n",
    "        label = labels[label_index]\n",
    "\n",
    "        for (root, dirs, files) in os.walk(in_path, topdown=True):\n",
    "            # number of elements in each split\n",
    "            n_train = math.floor(ratios[0] * len(files))\n",
    "            n_valid = math.floor(ratios[1] * len(files))\n",
    "            n_test = len(files) - (n_train + n_valid)\n",
    "\n",
    "            train_files = []\n",
    "            valid_files = []\n",
    "            test_files = []\n",
    "\n",
    "            # create list of random indexes and shuffle it\n",
    "            indexes = list(range(0, len(files)))\n",
    "            random.Random(seed).shuffle(indexes)\n",
    "\n",
    "            for j in range(0, len(files)):\n",
    "                index = indexes[j]\n",
    "                if j < n_train:\n",
    "                    train_files.append(files[index])\n",
    "                elif n_train <= j < n_train + n_valid:\n",
    "                    valid_files.append(files[index])\n",
    "                else:\n",
    "                    test_files.append(files[index])\n",
    "\n",
    "            for i, out_path in enumerate(out_paths):\n",
    "                if not os.path.exists(out_path + label + \"/\"): \n",
    "                    os.makedirs(out_path + label + \"/\") \n",
    "                else:\n",
    "                    utils.delete_folder(out_path + label + \"/\")\n",
    "                    os.makedirs(out_path + label + \"/\") \n",
    "\n",
    "                if i == 0:\n",
    "                    for filename in train_files:\n",
    "                        shutil.copyfile(in_path + filename, out_path + label +  \"/\" + filename)\n",
    "                elif i == 1:\n",
    "                    for filename in valid_files:\n",
    "                        shutil.copyfile(in_path + filename, out_path + label +  \"/\" + filename)\n",
    "                else:\n",
    "                    for filename in test_files:\n",
    "                        shutil.copyfile(in_path + filename, out_path + label +  \"/\" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder ../training-set/\n",
      "Created folder ../validation-set/\n",
      "Created folder ../test-set/\n"
     ]
    }
   ],
   "source": [
    "right_segments = \"/home/lorenzo/Documents/programming/mpai/manipulated-images/dataset-multiple/c/\"\n",
    "wrong_segments = \"/home/lorenzo/Documents/programming/mpai/manipulated-images/dataset-multiple/w/\"\n",
    "labels = ['c', 'w']\n",
    "\n",
    "in_paths = [right_segments, wrong_segments]\n",
    "\n",
    "train_path = \"../training-set/\"\n",
    "validation_path = \"../validation-set/\"\n",
    "test_path = \"../test-set/\"\n",
    "\n",
    "create_dataset(in_paths=in_paths, labels=labels, out_paths=[train_path, validation_path, test_path], ratios=[0.7, 0.2, 0.1], seed=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create dataset with four classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder ../dataset-four-classes-multiple/\n",
      "Created folder ../dataset-four-classes-multiple/double/\n",
      "Created folder ../dataset-four-classes-multiple/half/\n",
      "Created folder ../dataset-four-classes-multiple/quadruple/\n",
      "Created folder ../dataset-four-classes-multiple/quarter/\n",
      "Created folder ../training-set/\n",
      "Created folder ../validation-set/\n",
      "Created folder ../test-set/\n"
     ]
    }
   ],
   "source": [
    "wrong_segments = \"/home/lorenzo/Documents/programming/mpai/manipulated-images/dataset-nooverlap/w/\"\n",
    "new_dataset_path = \"../dataset-four-classes-multiple/\"\n",
    "\n",
    "labels = ['double', 'half', 'quadruple', 'quarter']\n",
    "\n",
    "utils.create_folder(new_dataset_path, overwrite=True)\n",
    "\n",
    "in_paths = []\n",
    "\n",
    "for label in labels:\n",
    "    utils.create_folder(new_dataset_path + label + \"/\", overwrite=True)\n",
    "    in_paths.append(new_dataset_path + label + \"/\")\n",
    "\n",
    "# add spectrograms to subdirectories depending on the name of the file\n",
    "for (root, dirs, files) in os.walk(wrong_segments, topdown=True):\n",
    "    for filename in files:\n",
    "        if \"3,75ips_to15ips\" in filename:\n",
    "            shutil.copyfile(wrong_segments + filename, new_dataset_path + 'quadruple' +  \"/\" + filename)\n",
    "        elif \"15ips_to3,75ips\" in filename:\n",
    "            shutil.copyfile(wrong_segments + filename, new_dataset_path + 'quarter' +  \"/\" + filename)\n",
    "        elif \"3,75ips_to7,5ips\" in filename:\n",
    "            shutil.copyfile(wrong_segments + filename, new_dataset_path + 'double' +  \"/\" + filename)\n",
    "        elif \"7,5ips_to15ips\" in filename:\n",
    "            shutil.copyfile(wrong_segments + filename, new_dataset_path + 'double' +  \"/\" + filename)\n",
    "        elif \"15ips_to7,5ips\" in filename:\n",
    "            shutil.copyfile(wrong_segments + filename, new_dataset_path + 'half' +  \"/\" + filename)\n",
    "        elif \"7,5ips_to3,75ips\" in filename:\n",
    "            shutil.copyfile(wrong_segments + filename, new_dataset_path + 'half' +  \"/\" + filename)\n",
    "\n",
    "\n",
    "train_path = \"../training-set/\"\n",
    "validation_path = \"../validation-set/\"\n",
    "test_path = \"../test-set/\"\n",
    "\n",
    "create_dataset(in_paths=in_paths, labels=labels, out_paths=[train_path, validation_path, test_path], ratios=[0.7, 0.2, 0.1], seed=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
